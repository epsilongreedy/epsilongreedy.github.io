[{"categories":["Books"],"content":"Summary 1984 is about an attempt to brainwash an entire nation into subservience. “The Party” controls nearly all aspects of its citizens' lives: when they get up and go to work, what they wear, what forms of entertainment they can engage in, what they are allowed to say and think. Every citizen’s home is equipped with a “telescreen” which is both a surveillance camera and a propaganda outlet. Needless to say, the smallest sign of nonconformity is punished by forced labour or death (or so it seems). Importantly, the system is very good at shaping its citizens' thoughts. Official news and other writings are continuously edited to depict the Party in good light. There is a (possibly made up) enemy of the state who is blamed for the Party’s failures, and serves as the universal target for all negative emotions. Children attend “education camps” from an early age and are encouraged to report nonconformist behaviour. ","date":"2020-12-12","objectID":"/posts/books/1984/:1:0","tags":null,"title":"1984","uri":"/posts/books/1984/"},{"categories":["Books"],"content":"Is the system evil?? It massively restricts individual freedom. People are killed or subjected to forced labour. Even among those who aren’t, many are unhappy. The system actively tries to reduce the diversity of conscious states. ","date":"2020-12-12","objectID":"/posts/books/1984/:2:0","tags":null,"title":"1984","uri":"/posts/books/1984/"},{"categories":["Books"],"content":"Breaking the system The system is hard to break because: Many people are genuinely brainwashed and loyal to the Party. The unorthodox have to continuously put up an appearance of orthodoxy, for risk of being reported. Virtually all public and private space is under surveillance. Hence there is nowhere to talk in private to organise a revolt. There is a task force, called the Thought Police, dedicated to detecting and dealing with unorthodoxy. The Thought Police is extremely well-informed and thorough. It is led by intelligent and devoted members of the Inner Party. ","date":"2020-12-12","objectID":"/posts/books/1984/:3:0","tags":null,"title":"1984","uri":"/posts/books/1984/"},{"categories":["Maths"],"content":"As a prerequisite, we will need Markov’s inequality. ","date":"2018-08-24","objectID":"/posts/maths/chernoff/:0:0","tags":null,"title":"Cramér-Chernoff bound","uri":"/posts/maths/chernoff/"},{"categories":["Maths"],"content":"Markov For a random variable \\( Z\\geq 0 \\), and \\( x\u003e0 \\), $$ \\mathbb{P}[Z \\geq x] \\leq \\frac{ \\mathbb{E}[Z]} {x}. $$ ","date":"2018-08-24","objectID":"/posts/maths/chernoff/:1:0","tags":null,"title":"Cramér-Chernoff bound","uri":"/posts/maths/chernoff/"},{"categories":["Maths"],"content":"Cramér-Chernoff This is an exponential bound, derived by applying Markov to exponentiated \\(Z\\), and optimising the RHS. For \\( \\lambda\\geq 0 \\), Markov implies $$ \\mathbb{P}[Z \\geq x] = \\mathbb{P}\\left[ e^{\\lambda Z} \\geq e^{\\lambda x} \\right] \\leq \\mathbb{E}\\left[e^{\\lambda Z}\\right] e^{-\\lambda x}. $$ Define the log moment-generating function of \\(Z\\), $$ \\psi_Z(\\lambda) = \\log\\mathbb{E}\\left[ e^{\\lambda Z} \\right], $$ and the Cramér transform of \\(Z \\), $$ \\psi^* _Z(x) = \\sup _{\\lambda \\geq 0} (\\lambda x - \\psi_Z(\\lambda)). $$ For a random variable \\( Z \\), and any \\( x \\), $$ \\mathbb{P}[Z \\geq x] \\leq \\exp(-\\psi_{Z}^*(x)). $$ ","date":"2018-08-24","objectID":"/posts/maths/chernoff/:2:0","tags":null,"title":"Cramér-Chernoff bound","uri":"/posts/maths/chernoff/"},{"categories":["Maths"],"content":"Consider binary classification. Let \\( (X, Y) \\) be random variables on \\( \\mathcal{X} \\times \\{0,1 \\} \\); denote by \\( P_X \\) the marginal distribution of \\( X \\), and by \\( \\eta(x) = \\mathbb{P}(Y=1|X=x) \\) the conditional probability of \\(Y\\) being one, given a value for \\(X\\). Clearly, some combinations of \\( (P_X, \\eta) \\) are more difficult to learn than others. The following condition on \\(P_X\\) and \\(\\eta\\) make learning fast: There exist constants \\(C\u003e0\\) and \\( \\alpha\\geq 0 \\) such that $$ P_X(|\\eta(X)- 1 / 2 |\\leq t) \\leq Ct^\\alpha. $$ The case \\( \\alpha=0 \\) is trivial (no assumption). The other extreme \\( \\alpha=\\infty \\) is very favourable for learning – it guarantees that \\( \\eta \\) is bounded away from \\( \\frac 1 2 \\). Here’s an alternative formulation of the Tsybakov condition: There exist constants \\(C\u003e0\\) and \\( \\beta\\in[0, 1] \\) such that every measurable \\( f:\\mathcal{X}\\to \\mathbb{R} \\) has $$ P_X( \\mathrm{sign} f(X) \\neq \\mathrm{sign}( \\eta(X) - 1 /2 )) \\leq C (R(f) - R^*)^\\beta, $$ where \\( R(f)-R^ * \\) is the excess risk, $$ R(f) = P(\\mathrm{sign} f(X) \\neq Y);\\ \\ \\ \\ R^ * = \\inf _{f} R(f). $$ ","date":"2018-08-22","objectID":"/posts/maths/tsybakov/:0:0","tags":null,"title":"Tsybakov's low-noise condition","uri":"/posts/maths/tsybakov/"}]